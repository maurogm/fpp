Chapter 09: ARIMA models
================
maurogm
2023-08-18

-   [Link](#link)
-   [Stationary and differencing](#stationary-and-differencing)
-   [Non-seasonal ARIMA models](#non-seasonal-arima-models)
    -   [ACF and PACF plots](#acf-and-pacf-plots)
-   [ARIMA modeling in fable](#arima-modeling-in-fable)
    -   [Example: Central African Republic
        exports](#example-central-african-republic-exports)
-   [Seasonal ARIMA models](#seasonal-arima-models)
    -   [Example: Monthly US leisure and hospitality
        employment](#example-monthly-us-leisure-and-hospitality-employment)

## Link

<https://otexts.com/fpp3/arima.html>

## Stationary and differencing

Vamos a ver ciertas herramientas de diagnóstico y tests para determinar
cuando una serie de tiempo es estacionaria.

``` r
google_2015 <- gafa_stock |>
  filter(Symbol == "GOOG", year(Date) == 2015)

p1 <- google_2015 |>
  ACF(Close) |>
  autoplot() + labs(subtitle = "Google closing stock price")
p2 <- google_2015 |>
  ACF(difference(Close)) |>
  autoplot() + labs(subtitle = "Changes in Google closing stock price")
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-1-1.png)<!-- -->

Como se ve en la serie, un test de ljung_box muesta que hay una clara
autocorrelación:

``` r
google_2015 |>
  features(Close, ljung_box, lag = 10)
```

    ## # A tibble: 1 × 3
    ##   Symbol lb_stat lb_pvalue
    ##   <chr>    <dbl>     <dbl>
    ## 1 GOOG     2083.         0

Después de diferenciar la serie, el test ya no muestra autocorrelación:

``` r
google_2015 |>
  mutate(diff_close = difference(Close)) |>
  features(diff_close, ljung_box, lag = 10)
```

    ## # A tibble: 1 × 3
    ##   Symbol lb_stat lb_pvalue
    ##   <chr>    <dbl>     <dbl>
    ## 1 GOOG      7.91     0.637

Exploramos una serie de tiempo de ventas de un fármaco, viendo que
debemos realizar distintas transformaciones para llevarla a una serie
estacionaria.

Primero tomamos logaritmo para estabilizar la varianza, luego
diferenciamos contra el año anterior para eliminar la estacionalidad (y
algo de la tendencia), pero todavía necesitamos una segunda
diferenciación para eliminar completamente la tendencia:

``` r
PBS_H02 <- PBS |>
  filter(ATC2 == "H02") |>
  summarise(Cost = sum(Cost) / 1e6)

PBS_H02 |>
  transmute(
    `Sales ($million)` = Cost,
    `Log sales` = log(Cost),
    `Annual change in log sales` = difference(log(Cost), 12),
    `Doubly differenced log sales` =
      difference(difference(log(Cost), 12), 1)
  ) |>
  pivot_longer(-Month, names_to = "Type", values_to = "Sales") |>
  mutate(
    Type = factor(Type, levels = c(
      "Sales ($million)",
      "Log sales",
      "Annual change in log sales",
      "Doubly differenced log sales"
    ))
  ) |>
  ggplot(aes(x = Month, y = Sales)) +
  geom_line() +
  facet_grid(vars(Type), scales = "free_y") +
  labs(title = "Corticosteroid drug sales", y = NULL)
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

La necesidad de esta última diferenciación no es completamente obvia,
por lo que es útil tener una herramienta algo más formal que nos ayude a
determinar esto. La función `unitroot_ndiffs` nos sugiere realizar una
diferenciaciones estacional:

``` r
PBS_H02 |>
  mutate(log_sales = log(Cost)) |>
  features(log_sales, unitroot_nsdiffs)
```

    ## # A tibble: 1 × 1
    ##   nsdiffs
    ##     <int>
    ## 1       1

Tras realizarla, la función `unitroot_ndiffs` nos sugiere realizar una
diferenciación adicional:

``` r
PBS_H02 |>
  mutate(log_sales_diff12 = difference(log(Cost), 12)) |>
  features(log_sales_diff12, unitroot_ndiffs)
```

    ## # A tibble: 1 × 1
    ##   ndiffs
    ##    <int>
    ## 1      1

Esta última función no está haciendo otra cosa más que aplicar el test
de KPSS sucesivamente hasta obtener un p-valor no significativo:

``` r
PBS_H02 |>
  mutate(log_sales_diff12 = difference(log(Cost), 12)) |>
  features(log_sales_diff12, unitroot_kpss)
```

    ## # A tibble: 1 × 2
    ##   kpss_stat kpss_pvalue
    ##       <dbl>       <dbl>
    ## 1     0.867        0.01

``` r
PBS_H02 |>
  mutate(log_sales_diff12 = difference(log(Cost), 12)) |>
  mutate(log_sales_diff12_diff1 = difference(difference(log(Cost), 12), 1)) |>
  features(log_sales_diff12_diff1, unitroot_kpss)
```

    ## # A tibble: 1 × 2
    ##   kpss_stat kpss_pvalue
    ##       <dbl>       <dbl>
    ## 1    0.0236         0.1

## Non-seasonal ARIMA models

Se usa de ejemplo el caso de las exportaciones de Egipto.

``` r
global_economy |>
  filter(Code == "EGY") |>
  autoplot(Exports) +
  labs(y = "% of GDP", title = "Egyptian exports")
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

Al usar la función `ARIMA`, se busca automáticamente cuáles son los
parámetros de p,d,q que mejor se ajustan a la serie.

``` r
fit <- global_economy |>
  filter(Code == "EGY") |>
  model(ARIMA(Exports))
report(fit)
```

    ## Series: Exports 
    ## Model: ARIMA(2,0,1) w/ mean 
    ## 
    ## Coefficients:
    ##          ar1      ar2      ma1  constant
    ##       1.6764  -0.8034  -0.6896    2.5623
    ## s.e.  0.1111   0.0928   0.1492    0.1161
    ## 
    ## sigma^2 estimated as 8.046:  log likelihood=-141.57
    ## AIC=293.13   AICc=294.29   BIC=303.43

Vemos que el modelo elegido es un `ARIMA(2,0,1) w/ mean`.

### ACF and PACF plots

Podríamos haber explorado la serie de tiempo usando los gráficos ACF y
PACF, para tratar de determinar a ojo los parámetros del modelo.

``` r
p_acf <- global_economy |>
  filter(Code == "EGY") |>
  ACF(Exports) |>
  autoplot()
p_pacf <- global_economy |>
  filter(Code == "EGY") |>
  PACF(Exports) |>
  autoplot()
gridExtra::grid.arrange(p_acf, p_pacf, ncol = 2)
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

(Una forma más cómoda de generar esos gráficos es con
`gg_tsdisplay(plot_type = "partial")`):

``` r
global_economy |>
  filter(Code == "EGY") %>%
  gg_tsdisplay(Exports, plot_type = "partial")
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->

Dado que el ACF tiene forma sinusoidal, y el último pico significativo
del PACF está en el lag 4, tiene sentido probar un modelo ARIMA(4, 0,
0).

``` r
fit2 <- global_economy |>
  filter(Code == "EGY") |>
  model(ARIMA(Exports ~ pdq(4, 0, 0)))
report(fit2)
```

    ## Series: Exports 
    ## Model: ARIMA(4,0,0) w/ mean 
    ## 
    ## Coefficients:
    ##          ar1      ar2     ar3      ar4  constant
    ##       0.9861  -0.1715  0.1807  -0.3283    6.6922
    ## s.e.  0.1247   0.1865  0.1865   0.1273    0.3562
    ## 
    ## sigma^2 estimated as 7.885:  log likelihood=-140.53
    ## AIC=293.05   AICc=294.7   BIC=305.41

Vemos que el modelo hecho a ojo tiene un desempeño muy similar al modelo
elegido por `ARIMA`:

``` r
list(fit, fit2) |>
  map(glance) |>
  bind_rows()
```

    ## # A tibble: 2 × 9
    ##   Country          .model     sigma2 log_lik   AIC  AICc   BIC ar_roots ma_roots
    ##   <fct>            <chr>       <dbl>   <dbl> <dbl> <dbl> <dbl> <list>   <list>  
    ## 1 Egypt, Arab Rep. ARIMA(Exp…   8.05   -142.  293.  294.  303. <cpl>    <cpl>   
    ## 2 Egypt, Arab Rep. ARIMA(Exp…   7.88   -141.  293.  295.  305. <cpl>    <cpl>

## ARIMA modeling in fable

### Example: Central African Republic exports

Vamos a ver un ejemplo completo de cómo sería el proceso completo para
desarrollar un modelo ARIMA, con y sin las automatizaciones de la
función `fable::ARIMA`. Trabajaremos con las exportaciones de la
República Centroafricana.

``` r
global_economy |>
  filter(Code == "CAF") |>
  autoplot(Exports) +
  labs(
    title = "Central African Republic exports",
    y = "% of GDP"
  )
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

Parece homocedástica, así que no le aplicamos ninguna transformación de
potencias.

La serie no es estacionaria, así que la diferenciamos:

``` r
global_economy |>
  filter(Code == "CAF") |>
  gg_tsdisplay(difference(Exports), plot_type = "partial")
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-15-1.png)<!-- -->

La serie diferenciada sí parece estacionaria, por lo que optamos por
d=1.

El PACF plot sugiere un modelo AR(2), pero el ACF plot sugiere un modelo
MA(3). Vamos a probar ambos modelos, junto con modelos elegidos
autmáticamente por ARIMA. También probaremos la diferencia entre usar la
búsqueda greedy default, y una búsqueda exhaustiva con `stepwise=FALSE`.

``` r
caf_fit <- global_economy |>
  filter(Code == "CAF") |>
  model(
    arima210 = ARIMA(Exports ~ pdq(2, 1, 0)),
    arima013 = ARIMA(Exports ~ pdq(0, 1, 3)),
    stepwise = ARIMA(Exports),
    search = ARIMA(Exports, stepwise = FALSE)
  )

caf_fit |> pivot_longer(!Country,
  names_to = "Model name",
  values_to = "Orders"
)
```

    ## # A mable: 4 x 3
    ## # Key:     Country, Model name [4]
    ##   Country                  `Model name`         Orders
    ##   <fct>                    <chr>               <model>
    ## 1 Central African Republic arima210     <ARIMA(2,1,0)>
    ## 2 Central African Republic arima013     <ARIMA(0,1,3)>
    ## 3 Central African Republic stepwise     <ARIMA(2,1,2)>
    ## 4 Central African Republic search       <ARIMA(3,1,0)>

Vemos que los modelos elegidos por `ARIMA` son distintos a los que
habíamos elegido a ojo.

No obstante, al ver como performan, vemos que todos tienen prácticamente
el mismo AICc:

``` r
glance(caf_fit) |>
  arrange(AICc) |>
  select(.model:BIC)
```

    ## # A tibble: 4 × 6
    ##   .model   sigma2 log_lik   AIC  AICc   BIC
    ##   <chr>     <dbl>   <dbl> <dbl> <dbl> <dbl>
    ## 1 search     6.52   -133.  274.  275.  282.
    ## 2 arima210   6.71   -134.  275.  275.  281.
    ## 3 arima013   6.54   -133.  274.  275.  282.
    ## 4 stepwise   6.42   -132.  274.  275.  284.

El modelo encontrado por la búqueda exahustiva es el mejor, lo que tiene
sentido. Lo curioso es que los dos modelos elegidos a ojo son mejores
que el encontrado por la búsqueda greedy.

Todavía no terminamos, dado que falta estudiar los residuos del modelo
para ver si son razonables.

``` r
caf_fit |>
  select(search) |>
  gg_tsresiduals()
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-18-1.png)<!-- -->

Los residuos parecen ser ruido blanco, sin autocorrelación y con una
distribución razonablemente gaussiana. Por las dudas hacemos un test
portmanteau de Ljung-Box con p+q grados de libertad:

``` r
augment(caf_fit) |>
  filter(.model == "search") |>
  features(.innov, ljung_box, lag = 10, dof = 3)
```

    ## # A tibble: 1 × 4
    ##   Country                  .model lb_stat lb_pvalue
    ##   <fct>                    <chr>    <dbl>     <dbl>
    ## 1 Central African Republic search    5.75     0.569

El p-valor alto apoya la observación que los residuos son ruido blanco,
por lo que podemos proceder a forecastear:

``` r
forecasts_arima <- caf_fit |>
  forecast(h = 5) |>
  filter(.model == "search")
forecasts_arima |>
  autoplot(global_economy)
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-20-1.png)<!-- -->

Es interesante que el forecast puntual es básicamente el de un modelo
Naive. La ventaja de usar un modelo ARIMA es que nos da intervalos de
confianza bastante más estrechos:

``` r
global_economy |>
  filter(Code == "CAF") |>
  model(naive = NAIVE(Exports)) |>
  forecast(h = 5) |>
  bind_rows(forecasts_arima) |>
  autoplot(global_economy, alpha = 0.6)
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-21-1.png)<!-- -->

## Seasonal ARIMA models

El capítulo de fpp tiene [una
sección](https://otexts.com/fpp3/seasonal-arima.html) en la que se
muestran dos ejemplos del procedimiento para ajustar un modelo ARIMA
estacional.

No agrega nada nuevo como para mostrarlo acá, más allá del hecho de que
en su segundo ejemplo el modelo al que se llega no pasa los tests de
residuos sin autocorrelación (a menos que se amplíe el espacio de
búsqueda usando ).

### Example: Monthly US leisure and hospitality employment

Veamos el workflow completo para ajustar un modelo ARIMA estacional.

``` r
leisure <- us_employment |>
  filter(Title == "Leisure and Hospitality",
         year(Month) > 2000) |>
  mutate(Employed = Employed/1000) |>
  select(Month, Employed)
autoplot(leisure, Employed) +
  labs(title = "US employment: leisure and hospitality",
       y="Number of people (millions)")
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-22-1.png)<!-- -->

Veamos los gráficos ACF y PACF con una diferenciación estacional:

``` r
leisure |>
  gg_tsdisplay(difference(Employed, 12),
               plot_type='partial', lag=36) +
  labs(title="Seasonally differenced", y="")
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-23-1.png)<!-- -->

Veamos agregando además una diferenciación no estacional:

``` r
leisure |>
  gg_tsdisplay(difference(Employed, 12) |> difference(),
               plot_type='partial', lag=36) +
  labs(title = "Double differenced", y="")
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-24-1.png)<!-- -->

A partir de los gráficos esbozamos un par de modelos a ojo, y los
comparamos con el modelo elegido por `ARIMA`:

``` r
fit <- leisure |>
  model(
    arima012011 = ARIMA(Employed ~ pdq(0,1,2) + PDQ(0,1,1)),
    arima210011 = ARIMA(Employed ~ pdq(2,1,0) + PDQ(0,1,1)),
    auto = ARIMA(Employed, stepwise = FALSE, approx = FALSE)
  )
fit |> pivot_longer(everything(), names_to = "Model name",
                     values_to = "Orders")
```

    ## # A mable: 3 x 2
    ## # Key:     Model name [3]
    ##   `Model name`                    Orders
    ##   <chr>                          <model>
    ## 1 arima012011  <ARIMA(0,1,2)(0,1,1)[12]>
    ## 2 arima210011  <ARIMA(2,1,0)(0,1,1)[12]>
    ## 3 auto         <ARIMA(2,1,0)(1,1,1)[12]>

``` r
glance(fit) |> arrange(AICc) |> select(.model:BIC)
```

    ## # A tibble: 3 × 6
    ##   .model       sigma2 log_lik   AIC  AICc   BIC
    ##   <chr>         <dbl>   <dbl> <dbl> <dbl> <dbl>
    ## 1 auto        0.00142    395. -780. -780. -763.
    ## 2 arima210011 0.00145    392. -776. -776. -763.
    ## 3 arima012011 0.00146    391. -775. -775. -761.

Dan bastante parecidos. Hagamos un análisis de residuos para ver si
pasan los tests de ruido blanco:

``` r
fit |> select(auto) |> gg_tsresiduals(lag=36)

augment(fit) |>
  filter(.model == "auto") |>
  features(.innov, ljung_box, lag=24, dof=4)
```

    ## # A tibble: 1 × 3
    ##   .model lb_stat lb_pvalue
    ##   <chr>    <dbl>     <dbl>
    ## 1 auto      16.6     0.680

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-26-1.png)<!-- -->

Los residuos parecen ser ruido blanco, por lo que podemos proceder a
forecastear:

``` r
forecast(fit, h=36) |>
  filter(.model=='auto') |>
  autoplot(leisure) +
  labs(title = "US employment: leisure and hospitality",
       y="Number of people (millions)")
```

![](/mnt/datassd/Estudio/fpp/rendered_files/ch_09_files/figure-gfm/unnamed-chunk-27-1.png)<!-- -->
