Chapter 05: The forecastr’s toolbox
================
maurogm
2022-12-27

-   [Link](#link)
-   [A tidy forecasting workflow](#a-tidy-forecasting-workflow)
-   [Some simple forecasting methods](#some-simple-forecasting-methods)
    -   [Example: Australian quarterly beer
        production](#example-australian-quarterly-beer-production)
-   [Fitted values and residuals](#fitted-values-and-residuals)
-   [Residual diagnostics](#residual-diagnostics)
    -   [Example: Forecasting Google daily closing stock
        prices](#example-forecasting-google-daily-closing-stock-prices)
    -   [Portmanteau tests for
        autocorrelation](#portmanteau-tests-for-autocorrelation)
-   [Distributional forecasts and prediction
    intervals](#distributional-forecasts-and-prediction-intervals)
    -   [Prediction intervals from bootstrapped
        residuals](#prediction-intervals-from-bootstrapped-residuals)
-   [Forecasting using
    transformations](#forecasting-using-transformations)
-   [Forecasting with decomposition](#forecasting-with-decomposition)
-   [Evaluating point forecast
    accuracy](#evaluating-point-forecast-accuracy)
-   [Evaluating distributional forecast
    accuracy](#evaluating-distributional-forecast-accuracy)
-   [Time series cross-validation](#time-series-cross-validation)

Más que nada se explorarán las capacidades del paquete `feasts`
(FEatures And Statistics from Time Series).

## Link

<https://otexts.com/fpp3/toolbox.html>

## A tidy forecasting workflow

``` r
gdppc <- global_economy %>%
  mutate(GDP_per_capita = GDP / Population)

gdppc %>%
  filter(Country == "Sweden") %>%
  autoplot(GDP_per_capita) +
  labs(y = "$US", title = "GDP per capita for Sweden")
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-1-1.png)<!-- -->

Fitea un modelo usando la función `TSLM` (time series linear model) del
paquete `fable` para fittear un linear trend model:

``` r
fit <- gdppc %>%
  model(trend_model = TSLM(GDP_per_capita ~ trend()))
fit
```

    ## # A mable: 263 x 2
    ## # Key:     Country [263]
    ##    Country             trend_model
    ##    <fct>                   <model>
    ##  1 Afghanistan              <TSLM>
    ##  2 Albania                  <TSLM>
    ##  3 Algeria                  <TSLM>
    ##  4 American Samoa           <TSLM>
    ##  5 Andorra                  <TSLM>
    ##  6 Angola                   <TSLM>
    ##  7 Antigua and Barbuda      <TSLM>
    ##  8 Arab World               <TSLM>
    ##  9 Argentina                <TSLM>
    ## 10 Armenia                  <TSLM>
    ## # … with 253 more rows

El resultado es un `mable` (model table), que se puede usar para
forecastear una `h` cantidad de períodos en el futuro, obteniendo un
`fable` (forecast table)\`:

``` r
fit %>% forecast(h = "3 years")
```

    ## # A fable: 789 x 5 [1Y]
    ## # Key:     Country, .model [263]
    ##    Country        .model       Year   GDP_per_capita  .mean
    ##    <fct>          <chr>       <dbl>           <dist>  <dbl>
    ##  1 Afghanistan    trend_model  2018     N(526, 9653)   526.
    ##  2 Afghanistan    trend_model  2019     N(534, 9689)   534.
    ##  3 Afghanistan    trend_model  2020     N(542, 9727)   542.
    ##  4 Albania        trend_model  2018  N(4716, 476419)  4716.
    ##  5 Albania        trend_model  2019  N(4867, 481086)  4867.
    ##  6 Albania        trend_model  2020  N(5018, 486012)  5018.
    ##  7 Algeria        trend_model  2018  N(4410, 643094)  4410.
    ##  8 Algeria        trend_model  2019  N(4489, 645311)  4489.
    ##  9 Algeria        trend_model  2020  N(4568, 647602)  4568.
    ## 10 American Samoa trend_model  2018 N(12491, 652926) 12491.
    ## # … with 779 more rows

Con el `fable` se puede hacer un `autoplot` para visualizar el forecast:

``` r
fit %>%
  forecast(h = "3 years") %>%
  filter(Country == "Sweden") %>%
  autoplot(gdppc) +
  labs(y = "$US", title = "GDP per capita for Sweden")
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

## Some simple forecasting methods

Esta sección explora métodos muy simples, a menudo útiles como baseline.

``` r
bricks <- aus_production %>%
  filter_index("1970 Q1" ~ "2004 Q4") %>% # convenient shorthand for extracting a section of a time series
  select(Bricks)
bricks
```

    ## # A tsibble: 140 x 2 [1Q]
    ##    Bricks Quarter
    ##     <dbl>   <qtr>
    ##  1    386 1970 Q1
    ##  2    428 1970 Q2
    ##  3    434 1970 Q3
    ##  4    417 1970 Q4
    ##  5    385 1971 Q1
    ##  6    433 1971 Q2
    ##  7    453 1971 Q3
    ##  8    436 1971 Q4
    ##  9    399 1972 Q1
    ## 10    461 1972 Q2
    ## # … with 130 more rows

#### MEAN

`MEAN` promedia los valores de la serie de tiempo:

``` r
bricks %>%
  model(MEAN(Bricks)) %>%
  forecast(h = "5 years") %>%
  autoplot(bricks)
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

#### Naive

`NAIVE` extiende el último valor de la serie de tiempo:

``` r
bricks %>%
  model(NAIVE(Bricks)) %>%
  forecast(h = "5 years") %>%
  autoplot(bricks)
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

Este método es óptimo si el fenómeno es un paseo al azar.

#### Seasonal Naive

Similar al Naive, pero cuando la serie de tiempo tiene una componente
estacional, `SNAIVE` extiende el último valor de la serie de tiempo en
cada estación:

``` r
bricks %>%
  model(SNAIVE(Bricks ~ lag("year"))) %>%
  forecast(h = "5 years") %>%
  autoplot(bricks)
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

El `lag` se necesita porque en algunos casos la serie de tiempo tiene
más de un perído estacional, y en esos casos hay que especificar cuál se
quiere usar.

#### Drift

Finalmente este método es similar al NAIVE (extiende el último valor),
pero permite ir variando de a poco el forecast. La variación que
introduce en cada unidad de tiempo es igual a la variación promedio
entre dos puntos sucesivos que observó en la data histórica:

``` r
bricks %>%
  model(NAIVE(Bricks ~ drift())) %>%
  forecast(h = "5 years") %>%
  autoplot(bricks)
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->

### Example: Australian quarterly beer production

``` r
# Set training data from 1992 to 2006
train <- aus_production %>%
  filter_index("1992 Q1" ~ "2006 Q4")
# Fit the models
beer_fit <- train %>%
  model(
    Mean = MEAN(Beer),
    `Naïve` = NAIVE(Beer),
    `Seasonal naïve` = SNAIVE(Beer)
  )
# Generate forecasts for 14 quarters
beer_fc <- beer_fit %>% forecast(h = 14)
beer_fc
```

    ## # A fable: 42 x 4 [1Q]
    ## # Key:     .model [3]
    ##    .model Quarter         Beer .mean
    ##    <chr>    <qtr>       <dist> <dbl>
    ##  1 Mean   2007 Q1 N(436, 1996)  436.
    ##  2 Mean   2007 Q2 N(436, 1996)  436.
    ##  3 Mean   2007 Q3 N(436, 1996)  436.
    ##  4 Mean   2007 Q4 N(436, 1996)  436.
    ##  5 Mean   2008 Q1 N(436, 1996)  436.
    ##  6 Mean   2008 Q2 N(436, 1996)  436.
    ##  7 Mean   2008 Q3 N(436, 1996)  436.
    ##  8 Mean   2008 Q4 N(436, 1996)  436.
    ##  9 Mean   2009 Q1 N(436, 1996)  436.
    ## 10 Mean   2009 Q2 N(436, 1996)  436.
    ## # … with 32 more rows

``` r
# Plot forecasts against actual values
beer_fc %>%
  autoplot(train, level = NULL) + # level=NULL avoids plotting ICs
  autolayer(
    filter_index(aus_production, "2007 Q1" ~ .),
    colour = "black"
  ) +
  labs(
    y = "Megalitres",
    title = "Forecasts for quarterly beer production"
  ) +
  guides(colour = guide_legend(title = "Forecast"))
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

## Fitted values and residuals

La función `augment` permite agregar a un `fable` los valores ajustados
y los residuos. Además incluye los “innovation residuals”, que en caso
de mostrar un patrón indican que el modelo todavía puede ser mejorado
(ver sección siguiente).

``` r
fabletools::augment(beer_fit)
```

    ## # A tsibble: 180 x 6 [1Q]
    ## # Key:       .model [3]
    ##    .model Quarter  Beer .fitted .resid .innov
    ##    <chr>    <qtr> <dbl>   <dbl>  <dbl>  <dbl>
    ##  1 Mean   1992 Q1   443    436.   6.55   6.55
    ##  2 Mean   1992 Q2   410    436. -26.4  -26.4 
    ##  3 Mean   1992 Q3   420    436. -16.4  -16.4 
    ##  4 Mean   1992 Q4   532    436.  95.6   95.6 
    ##  5 Mean   1993 Q1   433    436.  -3.45  -3.45
    ##  6 Mean   1993 Q2   421    436. -15.4  -15.4 
    ##  7 Mean   1993 Q3   410    436. -26.4  -26.4 
    ##  8 Mean   1993 Q4   512    436.  75.6   75.6 
    ##  9 Mean   1994 Q1   449    436.  12.6   12.6 
    ## 10 Mean   1994 Q2   381    436. -55.4  -55.4 
    ## # … with 170 more rows

## Residual diagnostics

Estas propiedades son condición necesaria para que un modelo sea bueno:

1.  The innovation residuals are uncorrelated. If there are correlations
    between innovation residuals, then there is information left in the
    residuals which should be used in computing forecasts.
2.  The innovation residuals have zero mean. If they have a mean other
    than zero, then the forecasts are biased.

Estas otras propiedades son deseables, pero no siempre se cumplen:

3.  The innovation residuals have constant variance. This is known as
    “homoscedasticity”.
4.  The innovation residuals are normally distributed.

### Example: Forecasting Google daily closing stock prices

Vamos a forecastear los precios de cierre de las acciones de Google:

``` r
google_stock <- gafa_stock %>%
  filter(Symbol == "GOOG", year(Date) >= 2015) %>%
  mutate(day = row_number()) %>%
  update_tsibble(index = day, regular = TRUE)
google_2015 <- google_stock %>% filter(year(Date) == 2015)
autoplot(google_2015, Close) +
  labs(
    y = "$US",
    title = "Google daily closing stock prices in 2015"
  )
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-12-1.png)<!-- -->

Para los precios de acciones, pocos modelos suelen ser mejores que el
naif (predecir el último valor observado). Fiteamos ese modelo, y
estudiamos sus residuos:

``` r
aug <- google_2015 %>%
  model(NAIVE(Close)) %>%
  augment()
autoplot(aug, .innov) +
  labs(
    y = "$US",
    title = "Residuals from the naïve method"
  )
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->

No parece haber autocorrelación en los residuos, y estos parecen
centrarse alrededor del 0. Vemos un histograma:

``` r
aug %>%
  ggplot(aes(x = .innov)) +
  geom_histogram() +
  labs(title = "Histogram of residuals")
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

Efectivamente se centran en 0, y son aproximadamente normales, aunque
con una cola un poco pesada a derecha.

Para ver mejor la autocorrelación, vemos las correlaciones entre los
residuos originales y todos sus lagas de 1 a 23:

``` r
aug %>%
  ACF(.innov) %>%
  autoplot() +
  labs(title = "Residuals from the naïve method")
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-15-1.png)<!-- -->

Una vez más, no encontramos autocorrelaciones.

Estos 3 gráficos son tan útiles que `feasts` tiene la función
`gg_tsresiduals` que los genera todos juntos:

``` r
google_2015 %>%
  model(NAIVE(Close)) %>%
  feasts::gg_tsresiduals()
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-16-1.png)<!-- -->

### Portmanteau tests for autocorrelation

Si se quiere hacer un test más formal de autocorrelación, se puede usar
un test de Portmanteau.

La idea de estos es similar a la del F-test. Dado que se consideran
muchos lags a la vez (por ejemplo en los gráficos de ACF anteriores), la
idea es controlar que las aparentes autocorrelaciones que puedan
aparecer no sean por azar.

Se proponen 2 tests, cuyos estadísticos son explicados en el texto.

Para calcular el test de **Box-Pierce**:

``` r
aug %>% features(.innov, box_pierce, lag = 10, dof = 0)
```

    ## # A tibble: 1 × 4
    ##   Symbol .model       bp_stat bp_pvalue
    ##   <chr>  <chr>          <dbl>     <dbl>
    ## 1 GOOG   NAIVE(Close)    7.74     0.654

Para calcular el test de **Ljung-Box**:

``` r
aug %>% features(.innov, ljung_box, lag = 10, dof = 0)
```

    ## # A tibble: 1 × 4
    ##   Symbol .model       lb_stat lb_pvalue
    ##   <chr>  <chr>          <dbl>     <dbl>
    ## 1 GOOG   NAIVE(Close)    7.91     0.637

En ambos casos se obtienen p-valores no significativos.

## Distributional forecasts and prediction intervals

Muchos métodos para calcular intervalos de predicción se basan en
supuestos sobre la distribución de los residuos, a menudo asumiendo que
son normales.

De este modo, podemos calcular el desvío estándar de los residuos y
pensar que el margen de error de nuestra predicción puntual será
proporcional a ese devío. A medida que aumenta el horizonte de
predicción, estos errores se acumulan, y por lo tanto el intervalo de
predicción se vuelve más amplio.

En `fabletools` se puede calcular un intervalo de predicción de este
tipo con la función `hilo`:

``` r
google_2015 %>%
  model(NAIVE(Close)) %>%
  forecast(h = 10) %>%
  hilo(level = c(80, 95, 99))
```

    ## # A tsibble: 10 x 8 [1]
    ## # Key:       Symbol, .model [1]
    ##    Symbol .model         day        Close .mean                  `80%`                  `95%`                  `99%`
    ##    <chr>  <chr>        <dbl>       <dist> <dbl>                 <hilo>                 <hilo>                 <hilo>
    ##  1 GOOG   NAIVE(Close)   253  N(759, 125)  759. [744.5400, 773.2200]80 [736.9488, 780.8112]95 [730.0575, 787.7025]99
    ##  2 GOOG   NAIVE(Close)   254  N(759, 250)  759. [738.6001, 779.1599]80 [727.8646, 789.8954]95 [718.1189, 799.6411]99
    ##  3 GOOG   NAIVE(Close)   255  N(759, 376)  759. [734.0423, 783.7177]80 [720.8941, 796.8659]95 [708.9580, 808.8020]99
    ##  4 GOOG   NAIVE(Close)   256  N(759, 501)  759. [730.1999, 787.5601]80 [715.0176, 802.7424]95 [701.2351, 816.5249]99
    ##  5 GOOG   NAIVE(Close)   257  N(759, 626)  759. [726.8147, 790.9453]80 [709.8404, 807.9196]95 [694.4310, 823.3290]99
    ##  6 GOOG   NAIVE(Close)   258  N(759, 751)  759. [723.7543, 794.0058]80 [705.1598, 812.6002]95 [688.2797, 829.4803]99
    ##  7 GOOG   NAIVE(Close)   259  N(759, 876)  759. [720.9399, 796.8202]80 [700.8556, 816.9045]95 [682.6230, 835.1371]99
    ##  8 GOOG   NAIVE(Close)   260 N(759, 1002)  759. [718.3203, 799.4397]80 [696.8493, 820.9108]95 [677.3578, 840.4022]99
    ##  9 GOOG   NAIVE(Close)   261 N(759, 1127)  759. [715.8599, 801.9001]80 [693.0865, 824.6735]95 [672.4126, 845.3474]99
    ## 10 GOOG   NAIVE(Close)   262 N(759, 1252)  759. [713.5329, 804.2272]80 [689.5275, 828.2325]95 [667.7354, 850.0246]99

Si se desea graficarlo, se puede usar `autoplot` directamente, sin pasar
por `hilo`:

``` r
google_2015 %>%
  model(NAIVE(Close)) %>%
  forecast(h = 10) %>%
  autoplot(google_2015, level = c(80, 95, 99)) +
  labs(title = "Google daily closing stock price", y = "$US")
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-20-1.png)<!-- -->

### Prediction intervals from bootstrapped residuals

A veces la asunción de normalidad de los residuos no es razonable. En
estos casos, se puede usar un método de bootstrap, que sólo asume que
los residuos son independientes y tienen varianza finita.

En este caso lo que hacemos es simular nuevos residuos bootstrapeados de
los residuos históricos, y usarlos para así ir construyendo una serie de
predicciones. La función `generate` nos puede ayudar en esta tarea:

``` r
fit <- google_2015 %>%
  model(NAIVE(Close))
sim <- fit %>% generate(h = 30, times = 5, bootstrap = TRUE)
sim
```

    ## # A tsibble: 150 x 5 [1]
    ## # Key:       Symbol, .model, .rep [5]
    ##    Symbol .model         day .rep   .sim
    ##    <chr>  <chr>        <dbl> <chr> <dbl>
    ##  1 GOOG   NAIVE(Close)   253 1      759.
    ##  2 GOOG   NAIVE(Close)   254 1      754.
    ##  3 GOOG   NAIVE(Close)   255 1      762.
    ##  4 GOOG   NAIVE(Close)   256 1      773.
    ##  5 GOOG   NAIVE(Close)   257 1      769.
    ##  6 GOOG   NAIVE(Close)   258 1      765.
    ##  7 GOOG   NAIVE(Close)   259 1      768.
    ##  8 GOOG   NAIVE(Close)   260 1      767.
    ##  9 GOOG   NAIVE(Close)   261 1      775.
    ## 10 GOOG   NAIVE(Close)   262 1      773.
    ## # … with 140 more rows

``` r
google_2015 %>%
  ggplot(aes(x = day)) +
  geom_line(aes(y = Close)) +
  geom_line(aes(y = .sim, colour = as.factor(.rep)),
    data = sim
  ) +
  labs(title = "Google daily closing stock price", y = "$US") +
  guides(colour = "none")
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-21-1.png)<!-- -->

Ahora, para calcular los intervalos de predicción, basta con simular una
cantidad arbitrarariamente grande de estas secuencias de predicciones, y
calcular los percentiles en función de la confianza que queramos darle.

La función `forecast` puede hacer esto por nosotros directamente con el
argumento `bootstrap`, ahorrándonos el trabajo de tener que simular:

``` r
fc <- fit %>% forecast(h = 30, bootstrap = TRUE, times = 4000)
fc
```

    ## # A fable: 30 x 5 [1]
    ## # Key:     Symbol, .model [1]
    ##    Symbol .model         day        Close .mean
    ##    <chr>  <chr>        <dbl>       <dist> <dbl>
    ##  1 GOOG   NAIVE(Close)   253 sample[4000]  759.
    ##  2 GOOG   NAIVE(Close)   254 sample[4000]  759.
    ##  3 GOOG   NAIVE(Close)   255 sample[4000]  759.
    ##  4 GOOG   NAIVE(Close)   256 sample[4000]  759.
    ##  5 GOOG   NAIVE(Close)   257 sample[4000]  759.
    ##  6 GOOG   NAIVE(Close)   258 sample[4000]  759.
    ##  7 GOOG   NAIVE(Close)   259 sample[4000]  759.
    ##  8 GOOG   NAIVE(Close)   260 sample[4000]  759.
    ##  9 GOOG   NAIVE(Close)   261 sample[4000]  759.
    ## 10 GOOG   NAIVE(Close)   262 sample[4000]  759.
    ## # … with 20 more rows

Pasando el objeto `fc` a `autoplot` se grafican los intervalos de
predicción:

``` r
autoplot(fc, google_2015, level = c(80, 95, 99)) +
  labs(title = "Google daily closing stock price", y = "$US")
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-23-1.png)<!-- -->

## Forecasting using transformations

Cuando se hacen forecasts de una serie trasnformada, procedemos igual y
después aplicamos la transformación inversa sobre las predicciones y los
intervalos. El texto muestra la inversa de la transformación de Box-Cox.

Al aplicar la inversa sobre una serie normal aparece un sesgo, en el
sentido de que la mediana se aparta de la media. Por más que la inversa
de las predicciones puntuales es la mediana, muchas veces es preferible
trabajar con las medias.

``` r
prices %>%
  filter(!is.na(eggs)) %>%
  model(RW(log(eggs) ~ drift())) %>%
  forecast(h = 50) %>%
  autoplot(prices %>% filter(!is.na(eggs)),
    level = 80, point_forecast = lst(mean, median)
  ) +
  labs(
    title = "Annual egg prices",
    y = "$US (in cents adjusted for inflation) "
  )
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-24-1.png)<!-- -->

## Forecasting with decomposition

Queremos hacer forecasts de una serie con estacionalidad. Vamos a
descomponer la serie y forecastear sus componentes por separado. A
menudo se asume que la estacinalidad es constante, por lo que el
“forecast” es simplemente el último valor del período.

Tomemos la serie de empleo en el sector retail de los Estados Unidos:

``` r
us_retail_employment <- us_employment %>%
  filter(year(Month) >= 1990, Title == "Retail Trade")
us_retail_employment %>% autoplot()

dcmp <- us_retail_employment %>%
  model(STL(Employed ~ trend(window = 7), robust = TRUE)) %>%
  components() %>%
  select(-.model)
dcmp
```

    ## # A tsibble: 357 x 7 [1M]
    ## # Key:       Series_ID [1]
    ##    Series_ID        Month Employed  trend season_year remainder season_adjust
    ##    <chr>            <mth>    <dbl>  <dbl>       <dbl>     <dbl>         <dbl>
    ##  1 CEU4200000001 1990 Jan   13256. 13326.       -72.6     2.85         13328.
    ##  2 CEU4200000001 1990 Feb   12966. 13297.      -273.    -58.1          13239.
    ##  3 CEU4200000001 1990 Mar   12938. 13270.      -295.    -36.3          13233.
    ##  4 CEU4200000001 1990 Apr   13012. 13230.      -216.     -1.59         13228.
    ##  5 CEU4200000001 1990 May   13108. 13223.      -119.      4.72         13228.
    ##  6 CEU4200000001 1990 Jun   13183. 13212.       -30.6     0.978        13213.
    ##  7 CEU4200000001 1990 Jul   13170. 13198.       -32.8     5.23         13203.
    ##  8 CEU4200000001 1990 Aug   13160. 13178.       -20.1     1.84         13180.
    ##  9 CEU4200000001 1990 Sep   13113. 13149.       -45.5     9.76         13159.
    ## 10 CEU4200000001 1990 Oct   13185. 13113.        64.2     8.28         13121.
    ## # … with 347 more rows

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-25-1.png)<!-- -->

Fitteamos la serie desestacionalizada, por ejemplo con un modelo NAIVE:

``` r
dcmp %>%
  model(NAIVE(season_adjust)) %>%
  forecast() %>%
  autoplot(dcmp) +
  labs(
    y = "Number of people",
    title = "US retail employment"
  )
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-26-1.png)<!-- -->

Y ahora habría que agregarle el componente estacional a los forecasts
para tener nuestro forecast final.

Todo esto puede hacerse en un solo paso con la función
`decomposition_model`. Se le pueden pasar los modelos a usar para cada
componente (y en caso de no especificar nada para la componente
estacional, se usa `SNAIVE`):

``` r
fit_dcmp <- us_retail_employment %>%
  model(stlf = decomposition_model(
    STL(Employed ~ trend(window = 7), robust = TRUE),
    NAIVE(season_adjust)
  ))
fit_dcmp %>%
  forecast() %>%
  autoplot(us_retail_employment) +
  labs(
    y = "Number of people",
    title = "US retail employment"
  )
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-27-1.png)<!-- -->

Es interesante que al ver los residuos, podemos notar que claramente hay
una autocirrelación en los mismos. Esto es porque nuestro modelo NAIVE
no está capturando el drift de tendencia.

``` r
fit_dcmp %>% gg_tsresiduals()
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-28-1.png)<!-- -->

## Evaluating point forecast accuracy

Nada muy novedoso.

-   Habla de train-test split.
-   Habla de errores como MAE, RMSE, MAPE y sMAPE.
-   Es interesante el “**MASE**” (Mean Absolute Scaled Error), que lo
    que hace es dividir a los errores por el error promedio de un modelo
    baseline (por ejemplo, un modelo NAIVE).

En el paquete `forecast` hay una función `accuracy` que nos permite
calcular todos estos errores:

``` r
recent_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
beer_train <- recent_production %>%
  filter(year(Quarter) <= 2007)

beer_fit <- beer_train %>%
  model(
    Mean = MEAN(Beer),
    `Naïve` = NAIVE(Beer),
    `Seasonal naïve` = SNAIVE(Beer),
    Drift = RW(Beer ~ drift())
  )

beer_fc <- beer_fit %>%
  forecast(h = 10)

beer_fc %>%
  autoplot(
    aus_production %>% filter(year(Quarter) >= 1992),
    level = NULL
  ) +
  labs(
    y = "Megalitres",
    title = "Forecasts for quarterly beer production"
  ) +
  guides(colour = guide_legend(title = "Forecast"))

accuracy(beer_fc, recent_production)
```

    ## # A tibble: 4 × 10
    ##   .model         .type    ME  RMSE   MAE    MPE  MAPE  MASE RMSSE    ACF1
    ##   <chr>          <chr> <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>   <dbl>
    ## 1 Drift          Test  -54.0  64.9  58.9 -13.6  14.6  4.12  3.87  -0.0741
    ## 2 Mean           Test  -13.8  38.4  34.8  -3.97  8.28 2.44  2.29  -0.0691
    ## 3 Naïve          Test  -51.4  62.7  57.4 -13.0  14.2  4.01  3.74  -0.0691
    ## 4 Seasonal naïve Test    5.2  14.3  13.4   1.15  3.17 0.937 0.853  0.132

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-29-1.png)<!-- -->

## Evaluating distributional forecast accuracy

En esta sección da scores para evaluar la calidad ya no de predicciones
puntuales, sino de forecasts de distribuciones.

-   **Quantile score**: Un score que para una cierta probabilidad p,
    considera la diferencia entre el p-cuantil y el valor real,
    castigando los errores cometidos cuando el valor real está más allá
    del p-cuantil.
-   **Winkler score**: Un score proporcional a la longitud del intervalo
    de confianza para un nivel alpha dado, que además castiga cuando el
    valor observado está por fuera del intervalo.
-   **CRPS**: Entiendo que es el más razonable… un promedio ponderado de
    los errores de predicción, pesando los errores por la distribución
    de probabilidad predicha.
-   **Skill score**: Es una forma de normalizar el score, parecido a lo
    que se hizo con el *MASE* para las predicciones puntuales. En este
    caso, se elige una métrica (por ejemplo el *CRPS*) y se calcula la
    mejora en esa métrica respecto a un modelo baseline (por ejemplo, un
    modelo NAIVE).

A conticuación mostramos cómo calcular estás métricas con la función
`accuracy`.

``` r
google_fit <- google_2015 %>%
  model(
    Mean = MEAN(Close),
    `Naïve` = NAIVE(Close),
    Drift = RW(Close ~ drift())
  )
google_jan_2016 <- google_stock %>%
  filter(yearmonth(Date) == yearmonth("2016 Jan"))
google_fc <- google_fit %>%
  forecast(google_jan_2016)

google_fc %>%
  filter(.model == "Naïve", Date == "2016-01-04") %>%
  accuracy(google_stock, list(qs=quantile_score), probs=0.10)
```

    ## # A tibble: 1 × 4
    ##   .model Symbol .type    qs
    ##   <chr>  <chr>  <chr> <dbl>
    ## 1 Naïve  GOOG   Test   4.86

``` r
google_fc %>%
  filter(.model == "Naïve", Date == "2016-01-04") %>%
  accuracy(google_stock,
    list(winkler = winkler_score), level = 80)
```

    ## # A tibble: 1 × 4
    ##   .model Symbol .type winkler
    ##   <chr>  <chr>  <chr>   <dbl>
    ## 1 Naïve  GOOG   Test     55.7

``` r
google_fc %>%
  accuracy(google_stock, list(crps = CRPS))
```

    ## # A tibble: 3 × 4
    ##   .model Symbol .type  crps
    ##   <chr>  <chr>  <chr> <dbl>
    ## 1 Drift  GOOG   Test   33.5
    ## 2 Mean   GOOG   Test   76.7
    ## 3 Naïve  GOOG   Test   26.5

``` r
google_fc %>%
  accuracy(google_stock, list(skill = skill_score(CRPS)))
```

    ## # A tibble: 3 × 4
    ##   .model Symbol .type  skill
    ##   <chr>  <chr>  <chr>  <dbl>
    ## 1 Drift  GOOG   Test  -0.266
    ## 2 Mean   GOOG   Test  -1.90 
    ## 3 Naïve  GOOG   Test   0

## Time series cross-validation

Habla de hacer cross-validation para series de tiempo agregando datos de
a uno y evaluando el modelo en cada paso.

Lo hace con la función `stretch_tsibble`, de la que podemos setear los
parámetros `.init` para indicar cuántos datos usar para como mínimo, y
`.step` para indicar cuántos datos agregar en cada paso.

``` r
google_2015_tr <- google_2015 %>%
  stretch_tsibble(.init = 3, .step = 1) %>%
  relocate(Date, Symbol, .id)
google_2015_tr
```

    ## # A tsibble: 31,875 x 10 [1]
    ## # Key:       Symbol, .id [250]
    ##    Date       Symbol   .id  Open  High   Low Close Adj_Close  Volume   day
    ##    <date>     <chr>  <int> <dbl> <dbl> <dbl> <dbl>     <dbl>   <dbl> <int>
    ##  1 2015-01-02 GOOG       1  526.  528.  521.  522.      522. 1447600     1
    ##  2 2015-01-05 GOOG       1  520.  521.  510.  511.      511. 2059800     2
    ##  3 2015-01-06 GOOG       1  512.  513.  498.  499.      499. 2899900     3
    ##  4 2015-01-02 GOOG       2  526.  528.  521.  522.      522. 1447600     1
    ##  5 2015-01-05 GOOG       2  520.  521.  510.  511.      511. 2059800     2
    ##  6 2015-01-06 GOOG       2  512.  513.  498.  499.      499. 2899900     3
    ##  7 2015-01-07 GOOG       2  504.  504.  497.  498.      498. 2065100     4
    ##  8 2015-01-02 GOOG       3  526.  528.  521.  522.      522. 1447600     1
    ##  9 2015-01-05 GOOG       3  520.  521.  510.  511.      511. 2059800     2
    ## 10 2015-01-06 GOOG       3  512.  513.  498.  499.      499. 2899900     3
    ## # … with 31,865 more rows

Con eso lo que hace es replicar la serie de tiempo varias veces
agregando los datos de a uno, e identificando cada repetición con la
variable `.id`.

Con todos estos “datasets” distintos, podemos entrenar un modelo para
cada uno y usar `accuracy` para evaluar las métricas sobre todos los
modelos:

``` r
google_2015_tr %>%
  model(RW(Close ~ drift())) %>%
  forecast(h = 1) %>%
  accuracy(google_2015)
```

    ## # A tibble: 1 × 11
    ##   .model              Symbol .type    ME  RMSE   MAE   MPE  MAPE  MASE RMSSE   ACF1
    ##   <chr>               <chr>  <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>
    ## 1 RW(Close ~ drift()) GOOG   Test  0.726  11.3  7.26 0.112  1.19  1.02  1.01 0.0985

Puedo comparar con la métrica sobre el modelo entrenado sobre el dataset
de entrenamiento entero:

``` r
google_2015 %>%
  model(RW(Close ~ drift())) %>%
  accuracy()
```

    ## # A tibble: 1 × 11
    ##   Symbol .model              .type           ME  RMSE   MAE     MPE  MAPE  MASE RMSSE   ACF1
    ##   <chr>  <chr>               <chr>        <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl>
    ## 1 GOOG   RW(Close ~ drift()) Training -2.97e-14  11.1  7.16 -0.0267  1.18  1.00 0.996 0.0976

Finalmente, veamos que podemos hacer este cross-validation con un
horizonte de forecast mayor a 1. A continuación hacemos lo mismo
forcasteando hasta 8 pasos más adelante, y vemos cómo el RMSE va
empeorando a medida que el horizonte de forecast aumenta:

``` r
fc <- google_2015_tr %>%
  model(RW(Close ~ drift())) %>%
  forecast(h = 8) %>%
  group_by(.id) %>%
  mutate(h = row_number()) %>%
  ungroup() %>%
  as_fable(response = "Close", distribution = Close)
fc %>%
  accuracy(google_2015, by = c("h", ".model")) %>%
  ggplot(aes(x = h, y = RMSE)) +
  geom_point()
```

![](/workspaces/fpp/rendered_files/ch_05_files/figure-gfm/unnamed-chunk-34-1.png)<!-- -->
